{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook demonstrates an end-to-end pipeline to improve topic modeling using <b> BERTopic </b> by reducing the noise cluster size while preserving coherence and diversity. Our method introduces an <b> objective function </b> that balances three competing goals: topic coherence, topic diversity, and noise reduction. Through <b> hyperparameter optimization (HPO) </b> with Optuna, we systematically search for the best configuration of UMAP and HDBSCAN parameters that maximize this objective.\n",
    "\n",
    "We apply our approach to the IMDb movie review dataset—a high-noise, real-world benchmark—and compare results against the baseline BERTopic configuration. Our method reduces noise from ~60% to ~40%, significantly increasing usable data and revealing richer topic structures.\n",
    "\n",
    "To ensure scalability, we leverage NVIDIA cuML to accelerate UMAP and HDBSCAN by adding a drop-in\n",
    "<b> %load_ext cuml.accel </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Acceleration (cuML) Activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 15:02:22.178] [CUML] [info] cuML: Installed accelerator for sklearn.\n",
      "[2025-06-16 15:02:23.732] [CUML] [info] cuML: Installed accelerator for umap.\n",
      "[2025-06-16 15:02:23.736] [CUML] [info] cuML: Installed accelerator for hdbscan.\n",
      "[2025-06-16 15:02:23.736] [CUML] [info] cuML: Successfully initialized accelerator.\n"
     ]
    }
   ],
   "source": [
    "%load_ext cuml.accel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJ-_3VvqBB9H"
   },
   "source": [
    "# BERTopic Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "z4fDkSgpzRYp",
    "outputId": "4fc48e67-d79f-4590-c4a4-7b7f27e30295"
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import hdbscan\n",
    "import umap\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load IMDb reviews dataset\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "docs = dataset[\"text\"]  # List of text documents\n",
    "\n",
    "# Create instances of GPU-accelerated UMAP and HDBSCAN\n",
    "umap_model = umap.UMAP(n_components=5, n_neighbors=15, min_dist=0.0, random_state = 42)\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_samples=10, gen_min_span_tree=True, prediction_data=True)\n",
    "\n",
    "# Pass the above models to be used in BERTopic\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# Visualize the topics\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> The Intertopic Distance Map visualization has been removed due to its large size. You can still generate it by running the notebook locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Topic ID and the Respective Top Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7rIMmjri5pn0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>14801</td>\n",
       "      <td>-1_the_to_and_of</td>\n",
       "      <td>[the, to, and, of, this, is, it, in, that, movie]</td>\n",
       "      <td>[Now, I have seen a lot of movies in my day, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "      <td>0_show_series_episode_episodes</td>\n",
       "      <td>[show, series, episode, episodes, season, show...</td>\n",
       "      <td>[\"That '70s Show\" is definitely the funniest s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "      <td>1_japanese_chinese_martial_japan</td>\n",
       "      <td>[japanese, chinese, martial, japan, arts, acti...</td>\n",
       "      <td>[Billy Chung Siu Hung's (the bloody swordplay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>461</td>\n",
       "      <td>2_bad_movie_worst_it</td>\n",
       "      <td>[bad, movie, worst, it, you, this, acting, was...</td>\n",
       "      <td>[Worst film ever, this is a statement that peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "      <td>3_horror_scary_movie_movies</td>\n",
       "      <td>[horror, scary, movie, movies, it, you, house,...</td>\n",
       "      <td>[(SPOILERS included) This film surely is the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>298</td>\n",
       "      <td>5</td>\n",
       "      <td>298_hutton_duchovny_geekboy_muldoon</td>\n",
       "      <td>[hutton, duchovny, geekboy, muldoon, jolie, jo...</td>\n",
       "      <td>[Okay, truthfully, I saw the previews for this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>299</td>\n",
       "      <td>5</td>\n",
       "      <td>299_elephant_elephants_plantation_taylor</td>\n",
       "      <td>[elephant, elephants, plantation, taylor, finc...</td>\n",
       "      <td>[A beautiful shopgirl in London is swept off h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>300_tomanovich_reverand_dara_mamets</td>\n",
       "      <td>[tomanovich, reverand, dara, mamets, kirkland,...</td>\n",
       "      <td>[This centers on unironic notions of coming to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>301_bombshells_elizabeth_dench_patrick</td>\n",
       "      <td>[bombshells, elizabeth, dench, patrick, laine,...</td>\n",
       "      <td>[A charming little film set in the UK about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>302</td>\n",
       "      <td>5</td>\n",
       "      <td>302_snowy_polynesian_zealand_river</td>\n",
       "      <td>[snowy, polynesian, zealand, river, pacific, a...</td>\n",
       "      <td>[Despite the rave reviews this flick has garne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                      Name  \\\n",
       "0       -1  14801                          -1_the_to_and_of   \n",
       "1        0    873            0_show_series_episode_episodes   \n",
       "2        1    505          1_japanese_chinese_martial_japan   \n",
       "3        2    461                      2_bad_movie_worst_it   \n",
       "4        3    341               3_horror_scary_movie_movies   \n",
       "..     ...    ...                                       ...   \n",
       "299    298      5       298_hutton_duchovny_geekboy_muldoon   \n",
       "300    299      5  299_elephant_elephants_plantation_taylor   \n",
       "301    300      5       300_tomanovich_reverand_dara_mamets   \n",
       "302    301      5    301_bombshells_elizabeth_dench_patrick   \n",
       "303    302      5        302_snowy_polynesian_zealand_river   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [the, to, and, of, this, is, it, in, that, movie]   \n",
       "1    [show, series, episode, episodes, season, show...   \n",
       "2    [japanese, chinese, martial, japan, arts, acti...   \n",
       "3    [bad, movie, worst, it, you, this, acting, was...   \n",
       "4    [horror, scary, movie, movies, it, you, house,...   \n",
       "..                                                 ...   \n",
       "299  [hutton, duchovny, geekboy, muldoon, jolie, jo...   \n",
       "300  [elephant, elephants, plantation, taylor, finc...   \n",
       "301  [tomanovich, reverand, dara, mamets, kirkland,...   \n",
       "302  [bombshells, elizabeth, dench, patrick, laine,...   \n",
       "303  [snowy, polynesian, zealand, river, pacific, a...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [Now, I have seen a lot of movies in my day, b...  \n",
       "1    [\"That '70s Show\" is definitely the funniest s...  \n",
       "2    [Billy Chung Siu Hung's (the bloody swordplay ...  \n",
       "3    [Worst film ever, this is a statement that peo...  \n",
       "4    [(SPOILERS included) This film surely is the b...  \n",
       "..                                                 ...  \n",
       "299  [Okay, truthfully, I saw the previews for this...  \n",
       "300  [A beautiful shopgirl in London is swept off h...  \n",
       "301  [This centers on unironic notions of coming to...  \n",
       "302  [A charming little film set in the UK about th...  \n",
       "303  [Despite the rave reviews this flick has garne...  \n",
       "\n",
       "[304 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the topic keywords\n",
    "topic_info = topic_model.get_topic_info()  # Returns a DataFrame with topic details\n",
    "topic_info  # Includes Topic ID and top keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy as cp\n",
    "noise_count = topic_info[topic_info.Topic == -1].Count\n",
    "float(cp.round((noise_count.values[0]/len(docs)) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization objective is an objective function represented as a weighted linear combination of three key metrics:\n",
    "<div align=\"center\">\n",
    "$$\n",
    "J = w_c \\cdot Coherence + w_d \\cdot Diversity - w_n \\cdot \\ max\\ (0,\\frac{(Noise \\; or \\; -1 \\; Cluster)\\% - Threshold}{100} )\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div> \n",
    "    Taking $w_c$ = 0.4, $w_d$ = 0.3, $w_n$ = 0.3, $Threshold$ = 20 for example, \n",
    "</div>\n",
    "<div align=\"center\">\n",
    "$$\n",
    "J = 0.4 \\cdot Coherence + 0.3 \\cdot Diversity - 0.3 \\cdot \\ max\\ (0,\\frac{(Noise \\; or \\; -1 \\; Cluster)\\% - 20}{100} )\n",
    "$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "# Preprocess and tokenize documents\n",
    "def preprocess(doc):\n",
    "    doc = re.sub(r'<.*?>', '', doc)  # Remove HTML\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc)  # Remove non-alphabetic chars\n",
    "    return doc.lower().split()\n",
    "\n",
    "# Extract topic words (excluding outlier topic -1)\n",
    "def get_topic_words(topic_model, topics):\n",
    "    return [\n",
    "        [word for word, _ in topic_model.get_topic(topic)]\n",
    "        for topic in set(topics) - {-1}\n",
    "    ]\n",
    "\n",
    "# Calculate the noise penalty\n",
    "def calculate_noise_penalty(topic_model, doc_count):\n",
    "    noise_row = topic_model.get_topic_info().query(\"Topic == -1\")\n",
    "    noise_count = int(noise_row.Count.values[0]) if not noise_row.empty else 0\n",
    "    noise_percent = cp.round((noise_count / doc_count) * 100, 2)\n",
    "    penalty = abs(noise_percent - 20)\n",
    "    return noise_percent, penalty\n",
    "\n",
    "# Calculate coherence score\n",
    "def calculate_coherence(topic_model, tokenized_docs, topics, dictionary):\n",
    "    topic_words = get_topic_words(topic_model, topics)\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_words,\n",
    "        texts=tokenized_docs,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "# Calculate topic diversity score\n",
    "def calculate_diversity(topic_model, topics):\n",
    "    topic_words = get_topic_words(topic_model, topics)\n",
    "    all_words = chain.from_iterable(topic_words)\n",
    "    word_list = list(all_words)\n",
    "    return len(set(word_list)) / len(word_list) if word_list else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation pipeline\n",
    "def train_and_eval(docs, n_components=5, n_neighbors=15, min_dist=0.0, min_samples=10,\n",
    "                   gen_min_span_tree=True, prediction_data=True):\n",
    "    try:\n",
    "        # Dimensionality reduction and clustering models\n",
    "        spread_val = max(min_dist + 1e-3, 1.0)\n",
    "        umap_model = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors,\n",
    "                               min_dist=min_dist, spread=spread_val)\n",
    "        hdbscan_model = hdbscan.HDBSCAN(min_samples=min_samples,\n",
    "                                        gen_min_span_tree=gen_min_span_tree,\n",
    "                                        prediction_data=prediction_data)\n",
    "\n",
    "        topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model)\n",
    "        topics, _ = topic_model.fit_transform(docs)\n",
    "\n",
    "        # Preprocess docs once\n",
    "        tokenized_docs = list(map(preprocess, docs))\n",
    "        dictionary = Dictionary(tokenized_docs)\n",
    "\n",
    "        # Metric calculations\n",
    "        noise_percent, penalty = calculate_noise_penalty(topic_model, len(docs))\n",
    "        coherence = calculate_coherence(topic_model, tokenized_docs, topics, dictionary)\n",
    "        diversity = calculate_diversity(topic_model, topics)\n",
    "\n",
    "        # Weighted score\n",
    "        score = (0.4 * coherence) + (0.3 * diversity) - (0.3 * penalty / 100)\n",
    "        return score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Trial failed] Exception: {e}\")\n",
    "        return -100.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (HPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_components\": trial.suggest_int(\"n_components\", 5, 20),\n",
    "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 5, 20),\n",
    "        \"min_dist\": trial.suggest_float(\"min_dist\", 0.0, 1.0),\n",
    "        \"min_samples\": trial.suggest_int(\"min_samples\", 5, 25),\n",
    "        \"gen_min_span_tree\": trial.suggest_categorical(\"gen_min_span_tree\", [True, False]),\n",
    "        \"prediction_data\": trial.suggest_categorical(\"prediction_data\", [True, False]),  \n",
    "    }\n",
    "    return train_and_eval(docs=docs, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:15:35,127] A new study created in memory with name: optuna_bertopic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:15:51.973] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:15:59,898] Trial 0 finished with value: 0.2585886740893275 and parameters: {'n_components': 19, 'n_neighbors': 13, 'min_dist': 0.6559847055064072, 'min_samples': 22, 'gen_min_span_tree': True, 'prediction_data': True}. Best is trial 0 with value: 0.2585886740893275.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:16:16.933] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:16:38,791] Trial 1 finished with value: 0.39402694288194373 and parameters: {'n_components': 11, 'n_neighbors': 17, 'min_dist': 0.7855316209877806, 'min_samples': 8, 'gen_min_span_tree': False, 'prediction_data': False}. Best is trial 1 with value: 0.39402694288194373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:16:55.829] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:17:04,156] Trial 2 finished with value: 0.22755259693611923 and parameters: {'n_components': 14, 'n_neighbors': 11, 'min_dist': 0.9578462739625135, 'min_samples': 22, 'gen_min_span_tree': False, 'prediction_data': True}. Best is trial 1 with value: 0.39402694288194373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:17:21.286] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:17:29,947] Trial 3 finished with value: 0.25855867408932753 and parameters: {'n_components': 16, 'n_neighbors': 13, 'min_dist': 0.8552674895776905, 'min_samples': 25, 'gen_min_span_tree': False, 'prediction_data': True}. Best is trial 1 with value: 0.39402694288194373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:17:47.197] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:18:03,011] Trial 4 finished with value: 0.3969103338719902 and parameters: {'n_components': 16, 'n_neighbors': 14, 'min_dist': 0.17615075495259813, 'min_samples': 20, 'gen_min_span_tree': True, 'prediction_data': True}. Best is trial 4 with value: 0.3969103338719902.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:18:19.734] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:18:28,197] Trial 5 finished with value: 0.2586486740893275 and parameters: {'n_components': 6, 'n_neighbors': 19, 'min_dist': 0.919979952129186, 'min_samples': 13, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 4 with value: 0.3969103338719902.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:18:44.840] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:19:03,844] Trial 6 finished with value: 0.3993301583667193 and parameters: {'n_components': 18, 'n_neighbors': 11, 'min_dist': 0.5024363814847549, 'min_samples': 14, 'gen_min_span_tree': False, 'prediction_data': False}. Best is trial 6 with value: 0.3993301583667193.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:19:21.161] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:19:35,801] Trial 7 finished with value: 0.3602612607986829 and parameters: {'n_components': 11, 'n_neighbors': 8, 'min_dist': 0.537753088603063, 'min_samples': 23, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 6 with value: 0.3993301583667193.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:19:52.978] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:20:11,850] Trial 8 finished with value: 0.3958639030397454 and parameters: {'n_components': 10, 'n_neighbors': 12, 'min_dist': 0.41410321525062666, 'min_samples': 16, 'gen_min_span_tree': True, 'prediction_data': True}. Best is trial 6 with value: 0.3993301583667193.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:20:28.364] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:20:47,884] Trial 9 finished with value: 0.41012372293006766 and parameters: {'n_components': 8, 'n_neighbors': 13, 'min_dist': 0.35778167444036124, 'min_samples': 13, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 9 with value: 0.41012372293006766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:21:04.739] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:22:34,765] Trial 10 finished with value: 0.4238033112251916 and parameters: {'n_components': 5, 'n_neighbors': 6, 'min_dist': 0.0856621756325428, 'min_samples': 5, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 10 with value: 0.4238033112251916.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:22:51.603] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:24:25,417] Trial 11 finished with value: 0.43095635637979335 and parameters: {'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.006038095781139979, 'min_samples': 5, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 11 with value: 0.43095635637979335.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:24:42.079] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:26:17,592] Trial 12 finished with value: 0.42267679278847486 and parameters: {'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.0231801885461784, 'min_samples': 5, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 11 with value: 0.43095635637979335.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:26:34.922] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:27:15,937] Trial 13 finished with value: 0.42899552852255635 and parameters: {'n_components': 7, 'n_neighbors': 5, 'min_dist': 0.005350668686725374, 'min_samples': 8, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 11 with value: 0.43095635637979335.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:27:32.818] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:28:04,631] Trial 14 finished with value: 0.41762493357797337 and parameters: {'n_components': 8, 'n_neighbors': 8, 'min_dist': 0.22660613306919541, 'min_samples': 9, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 11 with value: 0.43095635637979335.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:28:21.660] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:28:57,256] Trial 15 finished with value: 0.4160984707849811 and parameters: {'n_components': 8, 'n_neighbors': 8, 'min_dist': 0.239794161607893, 'min_samples': 9, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 11 with value: 0.43095635637979335.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:29:14.197] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:30:23,834] Trial 16 finished with value: 0.4339047428924338 and parameters: {'n_components': 7, 'n_neighbors': 5, 'min_dist': 0.0012105087172698276, 'min_samples': 7, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 16 with value: 0.4339047428924338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:30:40.854] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:31:12,040] Trial 17 finished with value: 0.4247040583210651 and parameters: {'n_components': 10, 'n_neighbors': 7, 'min_dist': 0.11928553834143374, 'min_samples': 11, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 16 with value: 0.4339047428924338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:31:28.990] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:31:47,305] Trial 18 finished with value: 0.4111306368703605 and parameters: {'n_components': 13, 'n_neighbors': 10, 'min_dist': 0.28222095137931086, 'min_samples': 17, 'gen_min_span_tree': False, 'prediction_data': False}. Best is trial 16 with value: 0.4339047428924338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:32:04.357] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:32:34,649] Trial 19 finished with value: 0.39295782217238157 and parameters: {'n_components': 5, 'n_neighbors': 16, 'min_dist': 0.34485406140919583, 'min_samples': 6, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 16 with value: 0.4339047428924338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:32:51.869] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:33:18,625] Trial 20 finished with value: 0.4281653736607506 and parameters: {'n_components': 7, 'n_neighbors': 9, 'min_dist': 0.11614095187671158, 'min_samples': 11, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 16 with value: 0.4339047428924338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:33:35.574] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:34:38,016] Trial 21 finished with value: 0.4300780064867389 and parameters: {'n_components': 7, 'n_neighbors': 5, 'min_dist': 0.006053230377275454, 'min_samples': 7, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 16 with value: 0.4339047428924338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:34:55.079] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:35:54,447] Trial 22 finished with value: 0.43720227759735714 and parameters: {'n_components': 9, 'n_neighbors': 6, 'min_dist': 0.0021612169364261147, 'min_samples': 7, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:36:11.938] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:36:44,094] Trial 23 finished with value: 0.4203556793466974 and parameters: {'n_components': 9, 'n_neighbors': 7, 'min_dist': 0.1491895612932953, 'min_samples': 10, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:37:01.313] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:38:00,677] Trial 24 finished with value: 0.42857334374774014 and parameters: {'n_components': 6, 'n_neighbors': 6, 'min_dist': 0.07274897583375675, 'min_samples': 7, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:38:17.440] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:39:36,718] Trial 25 finished with value: 0.41297708499067276 and parameters: {'n_components': 9, 'n_neighbors': 6, 'min_dist': 0.19056897574329767, 'min_samples': 5, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:39:53.308] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:40:36,657] Trial 26 finished with value: 0.42831085772894417 and parameters: {'n_components': 12, 'n_neighbors': 9, 'min_dist': 0.06959809405442266, 'min_samples': 7, 'gen_min_span_tree': False, 'prediction_data': True}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:40:53.260] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:41:18,716] Trial 27 finished with value: 0.41787947335202097 and parameters: {'n_components': 6, 'n_neighbors': 7, 'min_dist': 0.28458375701470495, 'min_samples': 11, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:41:35.895] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:42:15,635] Trial 28 finished with value: 0.41107165824176783 and parameters: {'n_components': 10, 'n_neighbors': 5, 'min_dist': 0.5722102382508596, 'min_samples': 6, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:42:33.077] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:42:50,741] Trial 29 finished with value: 0.3996944601873649 and parameters: {'n_components': 20, 'n_neighbors': 9, 'min_dist': 0.4253684658245429, 'min_samples': 18, 'gen_min_span_tree': True, 'prediction_data': True}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:43:08.082] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:43:30,133] Trial 30 finished with value: 0.40046380005015 and parameters: {'n_components': 9, 'n_neighbors': 15, 'min_dist': 0.7216519748157755, 'min_samples': 9, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:43:47.421] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:44:50,470] Trial 31 finished with value: 0.4299196363726815 and parameters: {'n_components': 7, 'n_neighbors': 5, 'min_dist': 0.0023900101400661407, 'min_samples': 7, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:45:07.851] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:45:53,153] Trial 32 finished with value: 0.42942273187676866 and parameters: {'n_components': 7, 'n_neighbors': 6, 'min_dist': 0.03237838187232781, 'min_samples': 8, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:46:10.597] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:47:29,096] Trial 33 finished with value: 0.41870547975942163 and parameters: {'n_components': 6, 'n_neighbors': 5, 'min_dist': 0.14844782847265728, 'min_samples': 6, 'gen_min_span_tree': True, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:47:46.196] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:48:29,469] Trial 34 finished with value: 0.4283902675174767 and parameters: {'n_components': 5, 'n_neighbors': 7, 'min_dist': 0.06959943207016685, 'min_samples': 8, 'gen_min_span_tree': False, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:48:46.566] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:49:06,952] Trial 35 finished with value: 0.4000443955721958 and parameters: {'n_components': 8, 'n_neighbors': 19, 'min_dist': 0.19589947603322433, 'min_samples': 10, 'gen_min_span_tree': True, 'prediction_data': True}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:49:23.979] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:50:55,418] Trial 36 finished with value: 0.4177026289782734 and parameters: {'n_components': 14, 'n_neighbors': 6, 'min_dist': 0.05706027163931862, 'min_samples': 5, 'gen_min_span_tree': False, 'prediction_data': False}. Best is trial 22 with value: 0.43720227759735714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:51:12.336] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:51:36,240] Trial 37 finished with value: 0.4399132307553768 and parameters: {'n_components': 11, 'n_neighbors': 10, 'min_dist': 0.0021227884589070994, 'min_samples': 12, 'gen_min_span_tree': True, 'prediction_data': True}. Best is trial 37 with value: 0.4399132307553768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:51:53.287] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:52:17,096] Trial 38 finished with value: 0.4199464121730489 and parameters: {'n_components': 12, 'n_neighbors': 11, 'min_dist': 0.12133431022641758, 'min_samples': 12, 'gen_min_span_tree': True, 'prediction_data': True}. Best is trial 37 with value: 0.4399132307553768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 14:52:34.502] [CUML] [info] Building knn graph using brute force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 14:52:52,877] Trial 39 finished with value: 0.39252737727258014 and parameters: {'n_components': 11, 'n_neighbors': 10, 'min_dist': 0.8433903744638245, 'min_samples': 15, 'gen_min_span_tree': False, 'prediction_data': True}. Best is trial 37 with value: 0.4399132307553768.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_components': 11, 'n_neighbors': 10, 'min_dist': 0.0021227884589070994, 'min_samples': 12, 'gen_min_span_tree': True, 'prediction_data': True}\n",
      "CPU times: user 54min 41s, sys: 3min, total: 57min 41s\n",
      "Wall time: 37min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"optuna_bertopic\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=142),\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply HPO best results to BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_val = max(study.best_params['min_dist'] + 1e-3, 1.0)\n",
    "n_components = study.best_params['n_components']\n",
    "n_neighbors = study.best_params['n_neighbors']\n",
    "min_dist = study.best_params['min_dist']\n",
    "min_samples = study.best_params['min_samples']\n",
    "gen_min_span_tree = study.best_params['gen_min_span_tree']\n",
    "prediction_data = study.best_params['prediction_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create instances of GPU-accelerated UMAP and HDBSCAN\n",
    "\n",
    "umap_model = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, spread=spread_val, random_state = 42)\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_samples=min_samples, gen_min_span_tree=gen_min_span_tree, prediction_data=prediction_data)\n",
    "\n",
    "# Pass the models to BERTopic\n",
    "topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model)\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# Visualize the topics\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> The Intertopic Distance Map visualization has been removed due to its large size. You can still generate it by running the notebook locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the cluster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>10007</td>\n",
       "      <td>-1_this_it_movie_was</td>\n",
       "      <td>[this, it, movie, was, to, the, br, that, and,...</td>\n",
       "      <td>[Firstly, I really enjoyed this movie and its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>0_horror_scarecrow_gore_scary</td>\n",
       "      <td>[horror, scarecrow, gore, scary, scarecrows, g...</td>\n",
       "      <td>[Scarecrows is one of those films that, with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>360</td>\n",
       "      <td>1_bollywood_indian_kapoor_akshay</td>\n",
       "      <td>[bollywood, indian, kapoor, akshay, khan, indi...</td>\n",
       "      <td>[Do not waste your time with this movie. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>2_french_paris_alexandre_la</td>\n",
       "      <td>[french, paris, alexandre, la, love, je, taime...</td>\n",
       "      <td>[I saw \"Paris Je T'Aime\" because a friend real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>3_martial_jackie_kung_arts</td>\n",
       "      <td>[martial, jackie, kung, arts, fu, chan, action...</td>\n",
       "      <td>[Jackie Chan's classic directorial feature POL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>601</td>\n",
       "      <td>5</td>\n",
       "      <td>601_show_smart_butterflies_jokes</td>\n",
       "      <td>[show, smart, butterflies, jokes, jackass, rea...</td>\n",
       "      <td>[I understand the jokes quite well, they just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>602</td>\n",
       "      <td>5</td>\n",
       "      <td>602_powell_vance_powells_philo</td>\n",
       "      <td>[powell, vance, powells, philo, astor, thin, a...</td>\n",
       "      <td>[I've seen the Thin Man series -- Powell and L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>603</td>\n",
       "      <td>5</td>\n",
       "      <td>603_suleiman_anansa_amin_linderby</td>\n",
       "      <td>[suleiman, anansa, amin, linderby, arab, caine...</td>\n",
       "      <td>[The story at the outset is interesting: slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>604</td>\n",
       "      <td>5</td>\n",
       "      <td>604_coulier_host_hosts_mustve</td>\n",
       "      <td>[coulier, host, hosts, mustve, kinnear, greg, ...</td>\n",
       "      <td>[In my opinion, this is a pretty good celebrit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>605</td>\n",
       "      <td>5</td>\n",
       "      <td>605_doc_docs_savage_bronze</td>\n",
       "      <td>[doc, docs, savage, bronze, hero, unlikable, e...</td>\n",
       "      <td>[DOC SAVAGE: THE MAN OF BRONZE (1 outta 5 star...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                               Name  \\\n",
       "0       -1  10007               -1_this_it_movie_was   \n",
       "1        0    377      0_horror_scarecrow_gore_scary   \n",
       "2        1    360   1_bollywood_indian_kapoor_akshay   \n",
       "3        2    204        2_french_paris_alexandre_la   \n",
       "4        3    198         3_martial_jackie_kung_arts   \n",
       "..     ...    ...                                ...   \n",
       "602    601      5   601_show_smart_butterflies_jokes   \n",
       "603    602      5     602_powell_vance_powells_philo   \n",
       "604    603      5  603_suleiman_anansa_amin_linderby   \n",
       "605    604      5      604_coulier_host_hosts_mustve   \n",
       "606    605      5         605_doc_docs_savage_bronze   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [this, it, movie, was, to, the, br, that, and,...   \n",
       "1    [horror, scarecrow, gore, scary, scarecrows, g...   \n",
       "2    [bollywood, indian, kapoor, akshay, khan, indi...   \n",
       "3    [french, paris, alexandre, la, love, je, taime...   \n",
       "4    [martial, jackie, kung, arts, fu, chan, action...   \n",
       "..                                                 ...   \n",
       "602  [show, smart, butterflies, jokes, jackass, rea...   \n",
       "603  [powell, vance, powells, philo, astor, thin, a...   \n",
       "604  [suleiman, anansa, amin, linderby, arab, caine...   \n",
       "605  [coulier, host, hosts, mustve, kinnear, greg, ...   \n",
       "606  [doc, docs, savage, bronze, hero, unlikable, e...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [Firstly, I really enjoyed this movie and its ...  \n",
       "1    [Scarecrows is one of those films that, with a...  \n",
       "2    [Do not waste your time with this movie. This ...  \n",
       "3    [I saw \"Paris Je T'Aime\" because a friend real...  \n",
       "4    [Jackie Chan's classic directorial feature POL...  \n",
       "..                                                 ...  \n",
       "602  [I understand the jokes quite well, they just ...  \n",
       "603  [I've seen the Thin Man series -- Powell and L...  \n",
       "604  [The story at the outset is interesting: slave...  \n",
       "605  [In my opinion, this is a pretty good celebrit...  \n",
       "606  [DOC SAVAGE: THE MAN OF BRONZE (1 outta 5 star...  \n",
       "\n",
       "[607 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the topic keywords\n",
    "topic_info = topic_model.get_topic_info()  # Returns a DataFrame with topic details\n",
    "topic_info  # Includes Topic ID and top keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Coherence Score (c_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.6562\n"
     ]
    }
   ],
   "source": [
    "tokenized_docs = list(map(preprocess, docs))\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "coherence = calculate_coherence(topic_model, tokenized_docs, topics, dictionary)\n",
    "print(f\"Coherence Score: {coherence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Diversity Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity Score: 0.7634\n"
     ]
    }
   ],
   "source": [
    "diversity = calculate_diversity(topic_model, topics)\n",
    "print(f\"Diversity Score: {diversity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Noise (-1 Cluster) Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Percentage: 41.2500\n"
     ]
    }
   ],
   "source": [
    "percent, penalty = calculate_noise_penalty(topic_model, len(docs))\n",
    "print(f\"Noise Percentage: {percent:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good c_v Coherence Score typically ranges:\n",
    "\n",
    "* above 0.5 = Acceptable\n",
    "\n",
    "* above 0.65 = Good\n",
    "\n",
    "* above 0.75 = Excellent\n",
    "\n",
    "And a good Diversity Score is usually ≥ 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Acceleration with NVIDIA cuML\n",
    "\n",
    "The CPU-based and GPU-accelerated approaches use identical code, with the only difference being the addition of <b>%load_ext cuml.accel</b> at the top of the notebook to enable GPU acceleration with cuML. This simple modification can significantly accelerate the K-Means and UMAP components of the BERTopic model—even within a single trial. You can try it yourself by running the below code on both CPU and GPU and comparing the execution times side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-16 15:25:47.289] [CUML] [info] build_algo set to brute_force_knn because random_state is given\n",
      "CPU times: user 53.7 s, sys: 1.88 s, total: 55.6 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from bertopic import BERTopic\n",
    "import hdbscan\n",
    "import umap\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load IMDb reviews dataset\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "docs = dataset[\"text\"] # List of text documents\n",
    "\n",
    "# Create instances of GPU-accelerated UMAP and HDBSCAN\n",
    "umap_model = umap.UMAP(n_components=5, n_neighbors=15, min_dist=0.0, random_state = 42)\n",
    "hdbscan_model = hdbscan.HDBSCAN(min_samples=10, gen_min_span_tree=True, prediction_data=True)\n",
    "\n",
    "# Pass the above models to be used in BERTopic\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
